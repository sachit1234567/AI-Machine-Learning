{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7DGbuYtB1JI",
        "outputId": "64399e0a-7008-4cfc-ff96-35f79bc82376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Function for Text Cleaning:\n",
        "\n",
        "Implement a Helper Function as per Text Preprocessing Notebook and Complete the following pipeline."
      ],
      "metadata": {
        "id": "SxV-QBHp-B6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Text Cleaning Pipeline"
      ],
      "metadata": {
        "id": "B-llg-TI_Drw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense, Dropout\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzVpeZbJwJ7u",
        "outputId": "8d25b14d-1e91-49bd-b957-1f26299fb65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_urls(text):\n",
        "  \"\"\"\n",
        "  This function will try to remove URL present in out dataset and replace it with space using regex library.\n",
        "  Input Args:\n",
        "  text: strings of text that may contain URLs.\n",
        "  Output Args:\n",
        "  text: URLs replaces with text\n",
        "  \"\"\"\n",
        "  url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return url_pattern.sub(r'', text)\n",
        "\n",
        "def remove_emoji(string):\n",
        "  \"\"\"\n",
        "  This function will replace the emoji in string with whitespace\n",
        "  \"\"\"\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "  return emoji_pattern.sub(r' ', string)\n",
        "\n",
        "def removeunwanted_characters(document):\n",
        "  \"\"\"\n",
        "  This function will remove all the unwanted characters from the input dataset.\n",
        "  Input Args:\n",
        "  documet: A text data to be cleaned.\n",
        "  Return:\n",
        "  A cleaned document.\n",
        "  \"\"\"\n",
        "  # remove user mentions\n",
        "  document = re.sub(\"@[A-Za-z0-9_]+\",\" \", document)\n",
        "  # remove hashtags\n",
        "  document = re.sub(\"#[A-Za-z0-9_]+\",\"\", document)\n",
        "  # remove punctuation\n",
        "  document = re.sub(\"[^0-9A-Za-z ]\", \"\" , document)\n",
        "  #remove emojis\n",
        "  document = remove_emoji(document)\n",
        "  # remove double spaces\n",
        "  document = document.replace('  ',\"\")\n",
        "  return document.strip()\n"
      ],
      "metadata": {
        "id": "s8MF1nPP691l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "def remove_punct(text):\n",
        "  \"\"\"\n",
        "  This function removes the punctutations present in our text data.\n",
        "  Input Args:\n",
        "  text: text data.\n",
        "  Returns:\n",
        "  text: cleaned text.\n",
        "  \"\"\"\n",
        "  tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "  lst=tokenizer.tokenize(' '.join(text))\n",
        "  return lst"
      ],
      "metadata": {
        "id": "qDk44aDk7Rfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "custom_stopwords = ['@', 'RT']\n",
        "stop_words.update(custom_stopwords)\n",
        "\n",
        "def remove_stopwords(text_tokens):\n",
        "  \"\"\"\n",
        "  This function removes all the stopwords present in out text tokens.\n",
        "  Input Args:\n",
        "  text_tokens: tokenize input of our datasets.\n",
        "  Returns:\n",
        "  result_tokens: list of token without stopword.\n",
        "  \"\"\"\n",
        "\n",
        "  result_tokens = []\n",
        "  for token in text_tokens:\n",
        "    if token not in stop_words:\n",
        "       result_tokens.append(token)\n",
        "  return result_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0N1Kkyk7Nr4",
        "outputId": "23b74215-6845-48ef-8373-3368eb249ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize,pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def lemmatization(token_text):\n",
        "  \"\"\"\n",
        "  This function performs the lemmatization operations as explained above.\n",
        "  Input Args:\n",
        "  token_text: list of tokens.\n",
        "  Returns:\n",
        "  lemmatized_tokens: list of lemmatized tokens.\n",
        "  \"\"\"\n",
        "  lemma_tokens = []\n",
        "  wordnet = WordNetLemmatizer()\n",
        "  lemmatized_tokens = [wordnet.lemmatize(token, pos = 'v') for token in token_text]\n",
        "\n",
        "  return lemmatized_tokens\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlpSVCSC7T7A",
        "outputId": "a74c8ee0-11bd-4240-e97c-f083c9135f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def stemming(text):\n",
        "  \"\"\"\n",
        "  This function performs stemming operations.\n",
        "  Input Args:\n",
        "  token_text: list of tokenize text.\n",
        "  Returns:\n",
        "  stemm_tokes: list of stemmed tokens.\n",
        "  \"\"\"\n",
        "  porter = PorterStemmer()\n",
        "  stemm_tokens = []\n",
        "  for word in text:\n",
        "    stemm_tokens.append(porter.stem(word))\n",
        "  return stemm_tokens"
      ],
      "metadata": {
        "id": "s3cnW-uu7Wiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lower_order(text):\n",
        "  \"\"\"\n",
        "  This function converts all the text in input text to lower order.\n",
        "  Input Args:\n",
        "  token_text : input text.\n",
        "  Returns:\n",
        "  small_order_text : text converted to small/lower order.\n",
        "  \"\"\"\n",
        "  small_order_text = text.lower()\n",
        "  return small_order_text\n",
        "\n",
        "# Test:\n",
        "sample_text = \"This Is some Normalized TEXT\"\n",
        "sample_small = lower_order(sample_text)\n",
        "print(sample_small)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hrtb-_Z7YjG",
        "outputId": "a29236a2-6b36-456b-8f84-8e750ec80358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is some normalized text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaning_pipeline(dataset, rule = \"lemmatize\"):\n",
        "  \"\"\"\n",
        "  This...\n",
        "  \"\"\"\n",
        "  # Convert the input to small/lower order.\n",
        "  data = lower_order(dataset)\n",
        "  # Remove URLs\n",
        "  data = remove_urls(data)\n",
        "  # Remove emojis\n",
        "  data = remove_emoji(data)\n",
        "  # Remove all other unwanted characters.\n",
        "  data = removeunwanted_characters(data)\n",
        "  # Create tokens.\n",
        "  tokens = data.split()\n",
        "  # Remove stopwords:\n",
        "  tokens = remove_stopwords(tokens)\n",
        "  # Stemming or Lemmatization\n",
        "  if rule == \"lemmatize\":\n",
        "    tokens = lemmatization(tokens)\n",
        "  elif rule == \"stem\":\n",
        "    tokens = stemming(tokens)\n",
        "  else:\n",
        "    print(\"Pick between lemmatize or stem\")\n",
        "\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "  # text = dataset.lower() # Lowercase\n",
        "  # text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Remove URLs\n",
        "  # text = re.sub(r'\\@\\w+|\\#', '', text) # Remove mentions/hashtags\n",
        "  # text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
        "  # text = re.sub(r'\\d+', '', text) # Remove numbers\n",
        "  # # Remove stopwords and lemmatize\n",
        "  # stop_words = set(stopwords.words('english'))\n",
        "  # tokens = text.split()\n",
        "  # if rule == \"lemmatize\":\n",
        "  #   lemmatizer = WordNetLemmatizer()\n",
        "  #   tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "  # elif rule == \"stem\":\n",
        "  #   tokens = [PorterStemmer().stem(word) for word in tokens if word not in stop_words]\n",
        "  # else:\n",
        "  #   print(\"Pick between lemmatize or stem\")\n",
        "  # return ' '.join(tokens)\n"
      ],
      "metadata": {
        "id": "KCT1T3-68tN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification using Machine Learning Models\n"
      ],
      "metadata": {
        "id": "hzMm4-1KCNkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📝 Instructions: Trump Tweet Sentiment Classification\n",
        "\n",
        "1. **Load the Dataset**  \n",
        "   Load the dataset named `\"trump_tweet_sentiment_analysis.csv\"` using `pandas`. Ensure the dataset contains at least two columns: `\"text\"` and `\"label\"`.\n",
        "\n",
        "2. **Text Cleaning and Tokenization**  \n",
        "   Apply a text preprocessing pipeline to the `\"text\"` column. This should include:\n",
        "   - Lowercasing the text  \n",
        "   - Removing URLs, mentions, punctuation, and special characters  \n",
        "   - Removing stopwords  \n",
        "   - Tokenization (optional: stemming or lemmatization)\n",
        "   - \"Complete the above function\"\n",
        "\n",
        "3. **Train-Test Split**  \n",
        "   Split the cleaned and tokenized dataset into **training** and **testing** sets using `train_test_split` from `sklearn.model_selection`.\n",
        "\n",
        "4. **TF-IDF Vectorization**  \n",
        "   Import and use the `TfidfVectorizer` from `sklearn.feature_extraction.text` to transform the training and testing texts into numerical feature vectors.\n",
        "\n",
        "5. **Model Training and Evaluation**  \n",
        "   Import **Logistic Regression** (or any machine learning model of your choice) from `sklearn.linear_model`. Train it on the TF-IDF-embedded training data, then evaluate it using the test set.  \n",
        "   - Print the **classification report** using `classification_report` from `sklearn.metrics`.\n"
      ],
      "metadata": {
        "id": "oFltIxr9L2Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xbjyNPszxSuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/trum_tweet_sentiment_analysis.csv')"
      ],
      "metadata": {
        "id": "74jOz-nvxY-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ew2Dvm7ixaVK",
        "outputId": "66ad9cfe-7c6a-419d-96b3-dc6c035a7604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  Sentiment\n",
              "0  RT @JohnLeguizamo: #trump not draining swamp b...          0\n",
              "1  ICYMI: Hackers Rig FM Radio Stations To Play A...          0\n",
              "2  Trump protests: LGBTQ rally in New York https:...          1\n",
              "3  \"Hi I'm Piers Morgan. David Beckham is awful b...          0\n",
              "4  RT @GlennFranco68: Tech Firm Suing BuzzFeed fo...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-936c9978-bf47-4e40-b1e4-75e3bc1daa38\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @JohnLeguizamo: #trump not draining swamp b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ICYMI: Hackers Rig FM Radio Stations To Play A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trump protests: LGBTQ rally in New York https:...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Hi I'm Piers Morgan. David Beckham is awful b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @GlennFranco68: Tech Firm Suing BuzzFeed fo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-936c9978-bf47-4e40-b1e4-75e3bc1daa38')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-936c9978-bf47-4e40-b1e4-75e3bc1daa38 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-936c9978-bf47-4e40-b1e4-75e3bc1daa38');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ad9dd135-0c10-4de6-9cae-a38ab36377a7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad9dd135-0c10-4de6-9cae-a38ab36377a7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ad9dd135-0c10-4de6-9cae-a38ab36377a7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text = df['text'].apply(text_cleaning_pipeline)"
      ],
      "metadata": {
        "id": "QsZsiIxS2p0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split FIRST (before tokenization)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "cleaned_text, # Features (text)\n",
        "df['Sentiment'], # Labels\n",
        "test_size=0.2,\n",
        "random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "q1Upr5Jh3Bs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "-AR84k4S33Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "# Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "y_pred = model.predict(X_test_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmInhuHc393o",
        "outputId": "23dcf7da-c06e-4d50-c244-026ac3952444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsGUEegY4lN2",
        "outputId": "556e1576-2087-48a0-890b-9ab5276ccc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96    248563\n",
            "           1       0.93      0.90      0.92    121462\n",
            "\n",
            "    accuracy                           0.95    370025\n",
            "   macro avg       0.94      0.94      0.94    370025\n",
            "weighted avg       0.95      0.95      0.95    370025\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SHFlWso5JJ3",
        "outputId": "1501c533-d500-4b5f-8279-12d3425f08f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[240616   7947]\n",
            " [ 11571 109891]]\n"
          ]
        }
      ]
    }
  ]
}